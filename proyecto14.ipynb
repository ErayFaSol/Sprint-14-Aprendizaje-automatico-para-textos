{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcipción del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Film Junky Union, una nueva comunidad vanguardista para los aficionados de las películas clásicas, está desarrollando un sistema para filtrar y categorizar reseñas de películas. Tu objetivo es entrenar un modelo para detectar las críticas negativas de forma automática. Para lograrlo, utilizarás un conjunto de datos de reseñas de películas de IMDB con leyendas de polaridad para construir un modelo para clasificar las reseñas positivas y negativas. Este deberá alcanzar un valor F1 de al menos 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, roc_curve, precision_recall_curve, roc_auc_score, average_precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Eduardo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuración de visualización\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "get_ipython().run_line_magic('config', \"InlineBackend.figure_format = 'png'\")\n",
    "# La siguiente línea proporciona gráficos de mejor calidad en pantallas HiDPI\n",
    "# get_ipython().run_line_magic('config', \"InlineBackend.figure_format = 'retina'\")\n",
    "# Utilizar estilo de Matplotlib\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Descargar los stopwords de nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\matplotlib\\style\\core.py:137\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     style \u001b[38;5;241m=\u001b[39m \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\matplotlib\\__init__.py:879\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[1;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[0;32m    878\u001b[0m rc_temp \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 879\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\matplotlib\\__init__.py:856\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    855\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname)\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInlineBackend.figure_format = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# la siguiente línea proporciona gráficos de mejor calidad en pantallas HiDPI\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# %config InlineBackend.figure_format = 'retina'\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseaborn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\matplotlib\\style\\core.py:139\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    137\u001b[0m         style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid package style, path of style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, URL of style file, or library style name (library \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyles are listed in `style.available`)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    143\u001b[0m filtered \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: 'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "# la siguiente línea proporciona gráficos de mejor calidad en pantallas HiDPI\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto es para usar progress_apply, puedes leer más en https://pypi.org/project/tqdm/#pandas-integration\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47331 entries, 0 to 47330\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   tconst           47331 non-null  object \n",
      " 1   title_type       47331 non-null  object \n",
      " 2   primary_title    47331 non-null  object \n",
      " 3   original_title   47331 non-null  object \n",
      " 4   start_year       47331 non-null  int64  \n",
      " 5   end_year         47331 non-null  object \n",
      " 6   runtime_minutes  47331 non-null  object \n",
      " 7   is_adult         47331 non-null  int64  \n",
      " 8   genres           47331 non-null  object \n",
      " 9   average_rating   47329 non-null  float64\n",
      " 10  votes            47329 non-null  Int64  \n",
      " 11  review           47331 non-null  object \n",
      " 12  rating           47331 non-null  int64  \n",
      " 13  sp               47331 non-null  object \n",
      " 14  pos              47331 non-null  int64  \n",
      " 15  ds_part          47331 non-null  object \n",
      " 16  idx              47331 non-null  int64  \n",
      "dtypes: Int64(1), float64(1), int64(5), object(10)\n",
      "memory usage: 6.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>title_type</th>\n",
       "      <th>primary_title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>runtime_minutes</th>\n",
       "      <th>is_adult</th>\n",
       "      <th>genres</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sp</th>\n",
       "      <th>pos</th>\n",
       "      <th>ds_part</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0068152</td>\n",
       "      <td>movie</td>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "      <td>1971</td>\n",
       "      <td>\\N</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy,Crime,Drama</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2218</td>\n",
       "      <td>The pakage implies that Warren Beatty and Gold...</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>8335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0068152</td>\n",
       "      <td>movie</td>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "      <td>1971</td>\n",
       "      <td>\\N</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy,Crime,Drama</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2218</td>\n",
       "      <td>How the hell did they get this made?! Presenti...</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>8336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0313150</td>\n",
       "      <td>short</td>\n",
       "      <td>'15'</td>\n",
       "      <td>'15'</td>\n",
       "      <td>2002</td>\n",
       "      <td>\\N</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy,Drama,Short</td>\n",
       "      <td>6.3</td>\n",
       "      <td>184</td>\n",
       "      <td>There is no real story the film seems more lik...</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>2489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0313150</td>\n",
       "      <td>short</td>\n",
       "      <td>'15'</td>\n",
       "      <td>'15'</td>\n",
       "      <td>2002</td>\n",
       "      <td>\\N</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy,Drama,Short</td>\n",
       "      <td>6.3</td>\n",
       "      <td>184</td>\n",
       "      <td>Um .... a serious film about troubled teens in...</td>\n",
       "      <td>7</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0313150</td>\n",
       "      <td>short</td>\n",
       "      <td>'15'</td>\n",
       "      <td>'15'</td>\n",
       "      <td>2002</td>\n",
       "      <td>\\N</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy,Drama,Short</td>\n",
       "      <td>6.3</td>\n",
       "      <td>184</td>\n",
       "      <td>I'm totally agree with GarryJohal from Singapo...</td>\n",
       "      <td>9</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst title_type primary_title original_title  start_year end_year  \\\n",
       "0  tt0068152      movie             $              $        1971       \\N   \n",
       "1  tt0068152      movie             $              $        1971       \\N   \n",
       "2  tt0313150      short          '15'           '15'        2002       \\N   \n",
       "3  tt0313150      short          '15'           '15'        2002       \\N   \n",
       "4  tt0313150      short          '15'           '15'        2002       \\N   \n",
       "\n",
       "  runtime_minutes  is_adult              genres  average_rating  votes  \\\n",
       "0             121         0  Comedy,Crime,Drama             6.3   2218   \n",
       "1             121         0  Comedy,Crime,Drama             6.3   2218   \n",
       "2              25         0  Comedy,Drama,Short             6.3    184   \n",
       "3              25         0  Comedy,Drama,Short             6.3    184   \n",
       "4              25         0  Comedy,Drama,Short             6.3    184   \n",
       "\n",
       "                                              review  rating   sp  pos  \\\n",
       "0  The pakage implies that Warren Beatty and Gold...       1  neg    0   \n",
       "1  How the hell did they get this made?! Presenti...       1  neg    0   \n",
       "2  There is no real story the film seems more lik...       3  neg    0   \n",
       "3  Um .... a serious film about troubled teens in...       7  pos    1   \n",
       "4  I'm totally agree with GarryJohal from Singapo...       9  pos    1   \n",
       "\n",
       "  ds_part   idx  \n",
       "0   train  8335  \n",
       "1   train  8336  \n",
       "2    test  2489  \n",
       "3    test  9280  \n",
       "4    test  9281  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_year</th>\n",
       "      <th>is_adult</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>rating</th>\n",
       "      <th>pos</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47331.000000</td>\n",
       "      <td>47331.000000</td>\n",
       "      <td>47329.000000</td>\n",
       "      <td>47329.0</td>\n",
       "      <td>47331.000000</td>\n",
       "      <td>47331.000000</td>\n",
       "      <td>47331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1989.631235</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>5.998278</td>\n",
       "      <td>25562.917323</td>\n",
       "      <td>5.484608</td>\n",
       "      <td>0.498954</td>\n",
       "      <td>6279.697999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.600364</td>\n",
       "      <td>0.041587</td>\n",
       "      <td>1.494289</td>\n",
       "      <td>83670.039163</td>\n",
       "      <td>3.473109</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>3605.702545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1894.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1982.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>827.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>3197.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>13974.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9412.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>1739448.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12499.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_year      is_adult  average_rating         votes        rating  \\\n",
       "count  47331.000000  47331.000000    47329.000000       47329.0  47331.000000   \n",
       "mean    1989.631235      0.001732        5.998278  25562.917323      5.484608   \n",
       "std       19.600364      0.041587        1.494289  83670.039163      3.473109   \n",
       "min     1894.000000      0.000000        1.400000           9.0      1.000000   \n",
       "25%     1982.000000      0.000000        5.100000         827.0      2.000000   \n",
       "50%     1998.000000      0.000000        6.300000        3197.0      4.000000   \n",
       "75%     2004.000000      0.000000        7.100000       13974.0      9.000000   \n",
       "max     2010.000000      1.000000        9.700000     1739448.0     10.000000   \n",
       "\n",
       "                pos           idx  \n",
       "count  47331.000000  47331.000000  \n",
       "mean       0.498954   6279.697999  \n",
       "std        0.500004   3605.702545  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000   3162.000000  \n",
       "50%        0.000000   6299.000000  \n",
       "75%        1.000000   9412.000000  \n",
       "max        1.000000  12499.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_reviews = pd.read_csv('datasets/imdb_reviews.tsv', sep='\\t', dtype={'votes': 'Int64'})\n",
    "\n",
    "display(df_reviews.info())\n",
    "display(df_reviews.head())\n",
    "display(df_reviews.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tconst             0\n",
      "title_type         0\n",
      "primary_title      0\n",
      "original_title     0\n",
      "start_year         0\n",
      "end_year           0\n",
      "runtime_minutes    0\n",
      "is_adult           0\n",
      "genres             0\n",
      "average_rating     2\n",
      "votes              2\n",
      "review             0\n",
      "rating             0\n",
      "sp                 0\n",
      "pos                0\n",
      "ds_part            0\n",
      "idx                0\n",
      "dtype: int64\n",
      "tconst             0\n",
      "title_type         0\n",
      "primary_title      0\n",
      "original_title     0\n",
      "start_year         0\n",
      "end_year           0\n",
      "runtime_minutes    0\n",
      "is_adult           0\n",
      "genres             0\n",
      "average_rating     0\n",
      "votes              0\n",
      "review             0\n",
      "rating             0\n",
      "sp                 0\n",
      "pos                0\n",
      "ds_part            0\n",
      "idx                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificación de valores nulos antes de la eliminación\n",
    "print(df_reviews.isnull().sum())\n",
    "\n",
    "# Eliminar filas con valores nulos\n",
    "df_reviews = df_reviews.dropna(subset=['average_rating', 'votes'])\n",
    "\n",
    "# Verificación de valores nulos después de la eliminación\n",
    "print(df_reviews.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificación de duplicados\n",
    "duplicados = df_reviews.duplicated().sum()\n",
    "print(f\"Número de filas duplicadas: {duplicados}\")\n",
    "\n",
    "# Si hay duplicados, eliminarlos\n",
    "if duplicados > 0:\n",
    "    df_reviews = df_reviews.drop_duplicates()\n",
    "    print(f\"Duplicados eliminados. Número de filas restantes: {len(df_reviews)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el número de películas y reseñas a lo largo de los años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "ax = axs[0]\n",
    "\n",
    "dft1 = df_reviews[['tconst', 'start_year']].drop_duplicates() \\\n",
    "    ['start_year'].value_counts().sort_index()\n",
    "dft1 = dft1.reindex(index=np.arange(dft1.index.min(), max(dft1.index.max(), 2021))).fillna(0)\n",
    "dft1.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Número de películas a lo largo de los años')\n",
    "\n",
    "ax = axs[1]\n",
    "\n",
    "dft2 = df_reviews.groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft2 = dft2.reindex(index=np.arange(dft2.index.min(), max(dft2.index.max(), 2021))).fillna(0)\n",
    "\n",
    "dft2.plot(kind='bar', stacked=True, label='#reviews (neg, pos)', ax=ax)\n",
    "\n",
    "dft2 = df_reviews['start_year'].value_counts().sort_index()\n",
    "dft2 = dft2.reindex(index=np.arange(dft2.index.min(), max(dft2.index.max(), 2021))).fillna(0)\n",
    "dft3 = (dft2/dft1).fillna(0)\n",
    "axt = ax.twinx()\n",
    "dft3.reset_index(drop=True).rolling(5).mean().plot(color='orange', label='reviews per movie (avg over 5 years)', ax=axt)\n",
    "\n",
    "lines, labels = axt.get_legend_handles_labels()\n",
    "ax.legend(lines, labels, loc='upper left')\n",
    "\n",
    "ax.set_title('Número de reseñas a lo largo de los años')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la distribución del número de reseñas por película con el conteo exacto y KDE (solo para saber cómo puede diferir del conteo exacto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "ax = axs[0]\n",
    "dft = df_reviews.groupby('tconst')['review'].count() \\\n",
    "    .value_counts() \\\n",
    "    .sort_index()\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_title('Gráfico de barras de #Reseñas por película')\n",
    "\n",
    "ax = axs[1]\n",
    "dft = df_reviews.groupby('tconst')['review'].count()\n",
    "sns.kdeplot(dft, ax=ax)\n",
    "ax.set_title('Gráfico KDE de #Reseñas por película')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['pos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax = axs[0]\n",
    "dft = df_reviews.query('ds_part == \"train\"')['rating'].value_counts().sort_index()\n",
    "dft = dft.reindex(index=np.arange(min(dft.index.min(), 1), max(dft.index.max(), 11))).fillna(0)\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_ylim([0, 5000])\n",
    "ax.set_title('El conjunto de entrenamiento: distribución de puntuaciones')\n",
    "\n",
    "ax = axs[1]\n",
    "dft = df_reviews.query('ds_part == \"test\"')['rating'].value_counts().sort_index()\n",
    "dft = dft.reindex(index=np.arange(min(dft.index.min(), 1), max(dft.index.max(), 11))).fillna(0)\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_ylim([0, 5000])\n",
    "ax.set_title('El conjunto de prueba: distribución de puntuaciones')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribución de reseñas negativas y positivas a lo largo de los años para dos partes del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(16, 8), gridspec_kw=dict(width_ratios=(2, 1), height_ratios=(1, 1)))\n",
    "\n",
    "ax = axs[0][0]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"train\"').groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft.index = dft.index.astype('int')\n",
    "dft = dft.reindex(index=np.arange(dft.index.min(), max(dft.index.max(), 2020))).fillna(0)\n",
    "dft.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set_title('El conjunto de entrenamiento: número de reseñas de diferentes polaridades por año')\n",
    "\n",
    "ax = axs[0][1]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"train\"').groupby(['tconst', 'pos'])['pos'].count().unstack()\n",
    "sns.kdeplot(dft[0], color='blue', label='negative', kernel='epa', ax=ax)\n",
    "sns.kdeplot(dft[1], color='green', label='positive', kernel='epa', ax=ax)\n",
    "ax.legend()\n",
    "ax.set_title('El conjunto de entrenamiento: distribución de diferentes polaridades por película')\n",
    "\n",
    "ax = axs[1][0]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"test\"').groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft.index = dft.index.astype('int')\n",
    "dft = dft.reindex(index=np.arange(dft.index.min(), max(dft.index.max(), 2020))).fillna(0)\n",
    "dft.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set_title('El conjunto de prueba: número de reseñas de diferentes polaridades por año')\n",
    "\n",
    "ax = axs[1][1]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"test\"').groupby(['tconst', 'pos'])['pos'].count().unstack()\n",
    "sns.kdeplot(dft[0], color='blue', label='negative', kernel='epa', ax=ax)\n",
    "sns.kdeplot(dft[1], color='green', label='positive', kernel='epa', ax=ax)\n",
    "ax.legend()\n",
    "ax.set_title('El conjunto de prueba: distribución de diferentes polaridades por película')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedimiento de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Composición de una rutina de evaluación que se pueda usar para todos los modelos en este proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "def evaluate_model(model, train_features, train_target, test_features, test_target):\n",
    "    \n",
    "    eval_stats = {}\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 6)) \n",
    "    \n",
    "    for type, features, target in (('train', train_features, train_target), ('test', test_features, test_target)):\n",
    "        \n",
    "        eval_stats[type] = {}\n",
    "    \n",
    "        pred_target = model.predict(features)\n",
    "        pred_proba = model.predict_proba(features)[:, 1]\n",
    "        \n",
    "        # F1\n",
    "        f1_thresholds = np.arange(0, 1.01, 0.05)\n",
    "        f1_scores = [metrics.f1_score(target, pred_proba>=threshold) for threshold in f1_thresholds]\n",
    "        \n",
    "        # ROC\n",
    "        fpr, tpr, roc_thresholds = metrics.roc_curve(target, pred_proba)\n",
    "        roc_auc = metrics.roc_auc_score(target, pred_proba)    \n",
    "        eval_stats[type]['ROC AUC'] = roc_auc\n",
    "\n",
    "        # PRC\n",
    "        precision, recall, pr_thresholds = metrics.precision_recall_curve(target, pred_proba)\n",
    "        aps = metrics.average_precision_score(target, pred_proba)\n",
    "        eval_stats[type]['APS'] = aps\n",
    "        \n",
    "        if type == 'train':\n",
    "            color = 'blue'\n",
    "        else:\n",
    "            color = 'green'\n",
    "\n",
    "        # Valor F1\n",
    "        ax = axs[0]\n",
    "        max_f1_score_idx = np.argmax(f1_scores)\n",
    "        ax.plot(f1_thresholds, f1_scores, color=color, label=f'{type}, max={f1_scores[max_f1_score_idx]:.2f} @ {f1_thresholds[max_f1_score_idx]:.2f}')\n",
    "        # establecer cruces para algunos umbrales        \n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(f1_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "            ax.plot(f1_thresholds[closest_value_idx], f1_scores[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('threshold')\n",
    "        ax.set_ylabel('F1')\n",
    "        ax.legend(loc='lower center')\n",
    "        ax.set_title(f'Valor F1') \n",
    "\n",
    "        # ROC\n",
    "        ax = axs[1]    \n",
    "        ax.plot(fpr, tpr, color=color, label=f'{type}, ROC AUC={roc_auc:.2f}')\n",
    "        # establecer cruces para algunos umbrales        \n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(roc_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'            \n",
    "            ax.plot(fpr[closest_value_idx], tpr[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('FPR')\n",
    "        ax.set_ylabel('TPR')\n",
    "        ax.legend(loc='lower center')        \n",
    "        ax.set_title(f'Curva ROC')\n",
    "        \n",
    "        # PRC\n",
    "        ax = axs[2]\n",
    "        ax.plot(recall, precision, color=color, label=f'{type}, AP={aps:.2f}')\n",
    "        # establecer cruces para algunos umbrales        \n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(pr_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "            ax.plot(recall[closest_value_idx], precision[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('recall')\n",
    "        ax.set_ylabel('precision')\n",
    "        ax.legend(loc='lower center')\n",
    "        ax.set_title(f'PRC')        \n",
    "\n",
    "        eval_stats[type]['Accuracy'] = metrics.accuracy_score(target, pred_target)\n",
    "        eval_stats[type]['F1'] = metrics.f1_score(target, pred_target)\n",
    "    \n",
    "    df_eval_stats = pd.DataFrame(eval_stats)\n",
    "    df_eval_stats = df_eval_stats.round(2)\n",
    "    df_eval_stats = df_eval_stats.reindex(index=('Exactitud', 'F1', 'APS', 'ROC AUC'))\n",
    "    \n",
    "    print(df_eval_stats)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponemos que todos los modelos a continuación aceptan textos en minúsculas y sin dígitos, signos de puntuación, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['review_norm'] = ...# <escribe tu código aquí>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División entrenamiento / prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fortuna, todo el conjunto de datos ya está dividido en partes de entrenamiento/prueba; 'ds_part' es el indicador correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_train = df_reviews.query('ds_part == \"train\"').copy()\n",
    "df_reviews_test = df_reviews.query('ds_part == \"test\"').copy()\n",
    "\n",
    "train_target = df_reviews_train['pos']\n",
    "test_target = df_reviews_test['pos']\n",
    "\n",
    "print(df_reviews_train.shape)\n",
    "print(df_reviews_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajar con modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 0 - Constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1 - NLTK, TF-IDF y LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model_1, train_features_1, train_target, test_features_1, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3 - spaCy, TF-IDF y LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_3(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    #tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    tokens = [token.lemma_ for token in doc]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 4 - spaCy, TF-IDF y LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Modelo 9 - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = transformers.BertConfig.from_pretrained('bert-base-uncased')\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT_text_to_embeddings(texts, max_length=512, batch_size=100, force_device=None, disable_progress_bar=False):\n",
    "    \n",
    "    ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    # texto al id de relleno de tokens junto con sus máscaras de atención \n",
    "       \n",
    "    # <escribe tu código aquí para crear ids_list y attention_mask_list>\n",
    "    \n",
    "    if force_device is not None:\n",
    "        device = torch.device(force_device)\n",
    "    else:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    model.to(device)\n",
    "    if not disable_progress_bar:\n",
    "        print(f'Uso del dispositivo {device}.')\n",
    "    \n",
    "    # obtener insertados en lotes\n",
    "    \n",
    "    embeddings = []\n",
    "\n",
    "    for i in tqdm(range(math.ceil(len(ids_list)/batch_size)), disable=disable_progress_bar):\n",
    "            \n",
    "        ids_batch = torch.LongTensor(ids_list[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "        # <escribe tu código aquí para crear attention_mask_batch\n",
    "            \n",
    "        with torch.no_grad():            \n",
    "            model.eval()\n",
    "            batch_embeddings = model(input_ids=ids_batch, attention_mask=attention_mask_batch)   \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].detach().cpu().numpy())\n",
    "        \n",
    "    return np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¡Atención! La ejecución de BERT para miles de textos puede llevar mucho tiempo en la CPU, al menos varias horas\n",
    "train_features_9 = BERT_text_to_embeddings(df_reviews_train['review_norm'], force_device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_reviews_train['review_norm'].shape)\n",
    "print(train_features_9.shape)\n",
    "print(train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si ya obtuviste los insertados, te recomendamos guardarlos para tenerlos listos si\n",
    "# np.savez_compressed('features_9.npz', train_features_9=train_features_9, test_features_9=test_features_9)\n",
    "\n",
    "# y cargar...\n",
    "# with np.load('features_9.npz') as data:\n",
    "#     train_features_9 = data['train_features_9']\n",
    "#     test_features_9 = data['test_features_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mis reseñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puedes eliminar por completo estas reseñas y probar tus modelos en tus propias reseñas; las que se muestran a continuación son solo ejemplos\n",
    "\n",
    "my_reviews = pd.DataFrame([\n",
    "    'I did not simply like it, not my kind of movie.',\n",
    "    'Well, I was bored and felt asleep in the middle of the movie.',\n",
    "    'I was really fascinated with the movie',    \n",
    "    'Even the actors looked really old and disinterested, and they got paid to be in the movie. What a soulless cash grab.',\n",
    "    'I didn\\'t expect the reboot to be so good! Writers really cared about the source material',\n",
    "    'The movie had its upsides and downsides, but I feel like overall it\\'s a decent flick. I could see myself going to see it again.',\n",
    "    'What a rotten attempt at a comedy. Not a single joke lands, everyone acts annoying and loud, even kids won\\'t like this!',\n",
    "    'Launching on Netflix was a brave move & I really appreciate being able to binge on episode after episode, of this exciting intelligent new drama.'\n",
    "], columns=['review'])\n",
    "\n",
    "\"\"\"\n",
    "my_reviews = pd.DataFrame([\n",
    "    'Simplemente no me gustó, no es mi tipo de película.',\n",
    "    'Bueno, estaba aburrido y me quedé dormido a media película.',\n",
    "    'Estaba realmente fascinada con la película',    \n",
    "    'Hasta los actores parecían muy viejos y desinteresados, y les pagaron por estar en la película. Qué robo tan desalmado.',\n",
    "    '¡No esperaba que el relanzamiento fuera tan bueno! Los escritores realmente se preocuparon por el material original',\n",
    "    'La película tuvo sus altibajos, pero siento que, en general, es una película decente. Sí la volvería a ver',\n",
    "    'Qué pésimo intento de comedia. Ni una sola broma tiene sentido, todos actúan de forma irritante y ruidosa, ¡ni siquiera a los niños les gustará esto!',\n",
    "    'Fue muy valiente el lanzamiento en Netflix y realmente aprecio poder seguir viendo episodio tras episodio de este nuevo drama tan emocionante e inteligente.'\n",
    "], columns=['review'])\n",
    "\"\"\"\n",
    "\n",
    "my_reviews['review_norm'] = ...# <escribe aquí la misma lógica de normalización que para el conjunto de datos principal>\n",
    "\n",
    "my_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = my_reviews['review_norm']\n",
    "\n",
    "my_reviews_pred_prob = model_2.predict_proba(tfidf_vectorizer_2.transform(texts))[:, 1]\n",
    "\n",
    "for i, review in enumerate(texts.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_prob[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = my_reviews['review_norm']\n",
    "\n",
    "my_reviews_pred_prob = model_3.predict_proba(tfidf_vectorizer_3.transform(texts.apply(lambda x: text_preprocessing_3(x))))[:, 1]\n",
    "\n",
    "for i, review in enumerate(texts.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_prob[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = my_reviews['review_norm']\n",
    "\n",
    "tfidf_vectorizer_4 = tfidf_vectorizer_3\n",
    "my_reviews_pred_prob = model_4.predict_proba(tfidf_vectorizer_4.transform(texts.apply(lambda x: text_preprocessing_3(x))))[:, 1]\n",
    "\n",
    "for i, review in enumerate(texts.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_prob[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = my_reviews['review_norm']\n",
    "\n",
    "my_reviews_features_9 = BERT_text_to_embeddings(texts, disable_progress_bar=True)\n",
    "\n",
    "my_reviews_pred_prob = model_9.predict_proba(my_reviews_features_9)[:, 1]\n",
    "\n",
    "for i, review in enumerate(texts.str.slice(0, 100)):\n",
    "    print(f'{my_reviews_pred_prob[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de comprobación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Abriste el notebook\n",
    "- [ ]  Cargaste y preprocesaste los datos de texto para su vectorización\n",
    "- [ ]  Transformaste los datos de texto en vectores\n",
    "- [ ]  Entrenaste y probaste los modelos\n",
    "- [ ]  Se alcanzó el umbral de la métrica\n",
    "- [ ]  Colocaste todas las celdas de código en el orden de su ejecución\n",
    "- [ ]  Puedes ejecutar sin errores todas las celdas de código \n",
    "- [ ]  Hay conclusiones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ac629f305345b17df6668bc9b17021b4f12075c260532782c34ed55a489bc20f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
